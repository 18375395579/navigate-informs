<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
<br>Title: Feature Selection for High-dimensional, Complex Models</br><br>Author: Saylisse Davila, Graduate Student, Arizona State University, Tempe, AZ, 85787-5906, United States of America, saylisse.davila@asu.edu</br><br>Year: 2008</br><br>Abstract: Learning a function that relates inputs to outputs is the objective of supervised learning.  As data sets become more extensive, the supervised learning task becomes more complex.  Feature selection is one of the typical strategies used to address this increased complexity in the model building process and respond to the curse of dimensionality. A robust feature selection method that can handle mixed (categorical and numerical) data, nonlinear relationships, interactions, and is insensitive to data quality such as missing values is important for many applications. We will present a methodology for feature selection for such cases. Our method uses simulated, artificial data to generate a compact subset of non-redundant features.  We will illustrate its effectiveness and computational ease on several simulated scenarios.</br>