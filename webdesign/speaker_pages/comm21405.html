<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" /><br>Title: A Coordinate Gradient Descent Method for Linearly Constrained Smooth Optimization</br><br>Author: Sangwoon Yun, National University of Singapore, Department of Mathematics, 2, Science Drive 2, Singapore, 117543, Singapore, matys@nus.edu.sg</br><br>Coauthor(s): Paul Tseng</br><br>Year: 2007</br><br>Abstract: We propose a (block) coordinate gradient descent method for solving a linearly constrained smooth optimization, including a large-scale quadratic problem arising in the training of support vector machines (SVMs). We establish global convergence and, under a local error bound assumption, linear rate of convergence for our method when the coordinate block is chosen by a Gauss-Southwell-type rule. Our numerical experience suggests that the method can be efficient for SVM  QP with nonlinear kernel.</br>