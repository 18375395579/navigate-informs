Title: A Structured Multiarmed Bandit Problem and the Greedy Policy<br>Author: Paat Rusmevichientong, paatrus@cornell.edu<br>Coauthor(s): Adam Mersereau, John Tsitsiklis<br>Year: 2008<br>Abstract: We consider a multiarmed bandit problem where the rewards of the arms are correlated through an unknown random variable with a prior distribution.  The objective is to choose a sequence of arms that maximizes the expected total or discounted total reward. We demonstrate the effectiveness of a greedy policy that takes advantage of the known statistical correlation structure among the arms.