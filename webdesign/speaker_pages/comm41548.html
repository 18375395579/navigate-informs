<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" /><br>Title: Knowledge Gradient For Bandit Problems</br><br>Author: Ilya Ryzhov, Princeton University, Department of ORFE, Princeton University, Princeton, NJ, 08544, United States of America, iryzhov@Princeton.EDU</br><br>Coauthor(s): Warren Powell</br><br>Year: 2008</br><br>Abstract: We derive a one-period look-ahead policy for a finite-horizon bandit problem with independent Gaussian rewards. The policy yields a computable algorithm for choosing arms. The resulting KG formula strikes a balance between exploration and exploitation, and always benefits from learning. However, information collection in this problem exhibits counter-intuitive properties: the marginal value of measuring one arm does not always diminish with the number of measurements.</br>