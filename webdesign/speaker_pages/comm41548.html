Title: Knowledge Gradient For Bandit Problems<br>Author: Ilya Ryzhov, Princeton University, Department of ORFE, Princeton University, Princeton, NJ, 08544, United States of America, iryzhov@Princeton.EDU<br>Coauthor(s): Warren Powell<br>Year: 2008<br>Abstract: We derive a one-period look-ahead policy for a finite-horizon bandit problem with independent Gaussian rewards. The policy yields a computable algorithm for choosing arms. The resulting KG formula strikes a balance between exploration and exploitation, and always benefits from learning. However, information collection in this problem exhibits counter-intuitive properties: the marginal value of measuring one arm does not always diminish with the number of measurements.