<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" /><br>Title: A Robust Stackelberg Solution Against Boundedly Rational Followers</br><br>Author: Albert Xin Jiang, University of Southern California, Dept of Computer Science, Los Angeles, CA, 90089, United States of America, albertjiang@gmail.com</br><br>Coauthor(s): Thanh Nguyen, Milind Tambe, Ariel Procaccia</br><br>Year: 2013</br><br>Abstract: There has been recent interest in applying Stackelberg games to  security, in which  a defender must protect targets from attack by an adaptive adversary.  In real-world settings the adversaries are boundedly rational.  Most existing approaches try to optimize against specific behavioral models of adversaries, and are not robust against modeling errors.   We propose a robust optimization approach, which provides guarantees against all adversary behavior satisfying certain regularity properties.</br>