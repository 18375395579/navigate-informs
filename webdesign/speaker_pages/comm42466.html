<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
<br>Title: Splitting of Randomized Stationary Policies in Total-reward Markov Decision Processes</br><br>Author: Eugene Feinberg, Professor, Stony Brook University, Department of Applied Mathematics, Stony Brook, NY, United States of America, efeinberg@notes.cc.sunysb.edu</br><br>Coauthor(s): Uriel G. Rothblum, Eric Denardo</br><br>Year: 2007</br><br>Abstract: For total-reward MDPs with Borel state and action sets, we present two results on splitting of a randomized stationary policy into a mixture of nonrandomized stationary policies. The first result is an explicit formula for the splitting at one state. The second result is a splitting of a randomized stationary policy that uses a finite number of randomization procedures.  We discuss applications of these results to countable discounted MDPs and to constrained bandit problems.</br>