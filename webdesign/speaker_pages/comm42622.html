<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
<br>Title: Strong Polynomiality of Policy Iterations for Average-cost MDPs Modeling Replacement and Maintenance</br><br>Author: Eugene Feinberg, Stony Brook University, Department of Applied Mathematics, Stony Brook, NY, United States of America, eugene.feinberg@stonybrook.edu</br><br>Coauthor(s): Jefferson Huang</br><br>Year: 2013</br><br>Abstract: This talk considers an average-cost Markov Decision Process (MDP) with finite state and action sets and satisfying the additional condition that there is a state to which the system jumps from any state and under  any action with a positive probability. The main result is that the policy iteration algorithm is strongly polynomial for such MDPs, which are often used to model replacement and maintenance problems.</br>