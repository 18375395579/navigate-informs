Title: Correlated Multiarmed Bandits<br>Author: Adam Mersereau, Assistant Professor, Kenan-Flagler Business School, University of North Carolina, Campus Box 3490, McColl Bldg., Chapel Hill, NC, 27599-3490, United States, amersere@chicagogsb.edu<br>Coauthor(s): Paat Rusmevichientong, John Tsitsiklis<br>Year: 2007<br>Abstract: The multiarmed bandit problem is a classic example of the exploration   vs. exploitation dilemma faced by decision-makers in environments with   data uncertainty.  To date, most research on the problem assumes the   arms are statistically independent.  Consequently, performances of   known algorithms scale with the number of arms.  We consider a setting   when the arms have an assumed correlation structure, and present   algorithms whose convergence rates are independent of the number of arms.