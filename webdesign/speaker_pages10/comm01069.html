<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
        <br>Title: Improving Repeated Labeling for Crowdsourced Data Annotation</br><br>Author: Sergiu Goschin, Computer Science Department, Rutgers University, Piscataway, NY, 08854, United States of America, sgoschin@gmail.com</br><br>Coauthor(s): Haym Hirsh</br><br>Year: 2013</br><br>Abstract: Crowdsourcing resources such as Amazon Mechanical Turk make it possible to label data cheaply, but often unreliability. A common approach for improving accuracy is to get labels from multiple workers, using their majority vote as the final label. We present a new approach, Beat-by-k, which obtains labels incrementally until one label is seen k more times than the other.  Our results show that Beat-by-k requires fewer labels to reach a given level of accuracy compared to other approaches.</br>