<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
        <br>Title: A Structured Multiarmed Bandit Problem and the Greedy Policy</br><br>Author: Paat Rusmevichientong, paatrus@cornell.edu</br><br>Coauthor(s): Adam Mersereau, John Tsitsiklis</br><br>Year: 2008</br><br>Abstract: We consider a multiarmed bandit problem where the rewards of the arms are correlated through an unknown random variable with a prior distribution.  The objective is to choose a sequence of arms that maximizes the expected total or discounted total reward. We demonstrate the effectiveness of a greedy policy that takes advantage of the known statistical correlation structure among the arms.</br>