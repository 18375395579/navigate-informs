<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" >
        <br>Title: Sufficiency of Markov Policies in Continuous-time Markov Decision Processes</br><br>Author: Manasa Mandava, Stony Brook University, Department of Applied Mathematics, Stony Brook, NY, United States of America, manasamandava@gmail.com</br><br>Coauthor(s): Eugene Feinberg, Albert Shiryaev</br><br>Year: 2013</br><br>Abstract: One of the basic facts in the theory of Discrete-Time Markov Decision Processes is that for any policy there exists a randomized Markov policy with the same marginal state-action distributions. This fact implies that for expected total (discounted) costs and average costs per unit time, it is sufficient to restrict the set of all policies to the set of randomized Markov policies. In this talk we present similar results for Continuous-Time Markov Decision Processes (CTMDPs).</br>